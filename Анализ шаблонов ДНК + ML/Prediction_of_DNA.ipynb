{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q # xgboost seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jT5XAscXQCX6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MayawWh0QSAQ"
   },
   "outputs": [],
   "source": [
    "train_data = './Training_dataset.csv'\n",
    "test_data  = './New_Validation_Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pk9ZmHlCQ_sF"
   },
   "outputs": [],
   "source": [
    "def getData(path):\n",
    "    \"\"\"\n",
    "    Функция для извлечения данных из текстового файла по заданному пути.\n",
    "\n",
    "    Данные должны быть организованы в файле таким образом, что каждая строка содержит метку и последовательность,\n",
    "    разделённые запятой. Первая строка файла, содержащая слово 'Label', игнорируется как заголовок.\n",
    "\n",
    "    Параметры:\n",
    "    path : str\n",
    "        Путь к файлу с данными для чтения.\n",
    "\n",
    "    Возвращает:\n",
    "    tuple\n",
    "        Возвращает кортеж из двух списков: первый список содержит последовательности (sequence),\n",
    "        а второй список содержит соответствующие метки (label).\n",
    "\n",
    "    Пример использования:\n",
    "    sequence, label = getData('path/to/your/data.txt')\n",
    "    \"\"\"\n",
    "    sequence = []\n",
    "    label = []\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            text_file = line.split(\",\")\n",
    "            if text_file[0] == 'Label':\n",
    "                continue\n",
    "            label.append(text_file[0])\n",
    "            sequence.append(text_file[1][:-1])\n",
    "\n",
    "    return sequence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufY7U3SWRZty",
    "outputId": "8a3f6010-1951-433f-d796-2598c1c7a58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имеется 38910 количество доступных образцов ДНК.\n"
     ]
    }
   ],
   "source": [
    "# Отделяет как метки, так и строку\n",
    "x_train, y_train = getData(train_data)\n",
    "\n",
    "print('Имеется',len(y_train),'количество доступных образцов ДНК.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iSmhAUgRR_Bh"
   },
   "outputs": [],
   "source": [
    "# Извлечение признаков дипептидов, в этом случае 780 признаков. Комбинация двух признаков с аминокислотной последовательностью\n",
    "aminoacid_sequence = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "\n",
    "dipeptide_seq = []\n",
    "\n",
    "for charone in aminoacid_sequence:\n",
    "    for chartwo in aminoacid_sequence:\n",
    "        char_to_add = charone+chartwo\n",
    "        char_to_addback = chartwo + charone\n",
    "        dipeptide_seq.append(char_to_add)\n",
    "        if char_to_add == char_to_addback:\n",
    "            continue\n",
    "        dipeptide_seq.append(char_to_addback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c7xAVkeBSTry"
   },
   "outputs": [],
   "source": [
    "# Здесь для каждой последовательности извлекается 780 признаков дипептида с помощью расчетов дипептидов\n",
    "def get_dipeptide_dictionary(string):\n",
    "    \"\"\"\n",
    "    Функция для создания словаря дипептидов из заданной строки.\n",
    "\n",
    "    Для каждой возможной пары символов в строке (включая смежные и через один символ) функция вычисляет\n",
    "    относительную частоту каждой уникальной комбинации в строке. Относительная частота вычисляется как\n",
    "    количество появлений комбинации, делённое на общую длину входной строки.\n",
    "\n",
    "    Параметры:\n",
    "    string : str\n",
    "        Входная строка, для которой необходимо вычислить дипептидный словарь.\n",
    "\n",
    "    Возвращает:\n",
    "    dict\n",
    "        Словарь, где ключами являются возможные комбинации двух символов (дипептиды), а значениями — их относительная частота\n",
    "        во входной строке. Относительная частота рассчитывается как количество появлений дипептида, делённое на длину строки.\n",
    "\n",
    "    Пример использования:\n",
    "    dipeptide_dict = get_dipeptide_dictionary(\"ABCD\")\n",
    "    # Возвращает словарь вида {'AB': 0.25, 'BC': 0.25, 'CD': 0.25, 'AC': 0.25, 'BD': 0.25}\n",
    "    \"\"\"\n",
    "    # Инициализация переменных\n",
    "    size = len(string)  # Длина входной строки\n",
    "    i = 0\n",
    "    eachseq_list = []   # Список для хранения всех дипептидов\n",
    "\n",
    "    # Генерация дипептидов из смежных символов\n",
    "    while i < size - 1:\n",
    "        add_seq = string[i] + string[i+1]\n",
    "        eachseq_list.append(add_seq)\n",
    "        i += 1\n",
    "\n",
    "    # Генерация дипептидов с пропуском одного символа\n",
    "    i = 0\n",
    "    while i < size - 2:\n",
    "        add_seq = string[i] + string[i+2]\n",
    "        eachseq_list.append(add_seq)\n",
    "        i += 1\n",
    "\n",
    "    # Создание словаря для подсчёта вхождений каждого дипептида\n",
    "    getdict = {}\n",
    "    for item in eachseq_list:\n",
    "        if item not in getdict:\n",
    "            getdict[item] = 1\n",
    "        else:\n",
    "            getdict[item] += 1\n",
    "\n",
    "    # Подсчёт относительной частоты каждого дипептида\n",
    "    new_dict = {}\n",
    "    for item, count in getdict.items():\n",
    "        new_dict[item] = count / size\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NRp2ULi4TgGE"
   },
   "outputs": [],
   "source": [
    "# Эти две функции помогают нам создать вектор для каждой последовательности\n",
    "def getlist_of_dictionary(x_train):\n",
    "    \"\"\"\n",
    "    Преобразует список строк в список словарей дипептидных векторов.\n",
    "\n",
    "    Каждый элемент списка представляет собой словарь, генерируемый функцией get_dipeptide_dictionary,\n",
    "    для соответствующей строки в x_train.\n",
    "\n",
    "    Параметры:\n",
    "    x_train : list of str\n",
    "        Список строк, для которых нужно сгенерировать дипептидные словари.\n",
    "\n",
    "    Возвращает:\n",
    "    list of dict\n",
    "        Список словарей дипептидных векторов для каждой строки в x_train.\n",
    "\n",
    "    Пример использования:\n",
    "    list_dictionary = getlist_of_dictionary([\"ABCD\", \"XYZ\"])\n",
    "    # Возвращает список словарей с дипептидными векторами для каждой строки.\n",
    "    \"\"\"\n",
    "    list_dictionary = []  # Инициализация списка для хранения словарей\n",
    "\n",
    "    # Перебор каждой строки в входном списке\n",
    "    for each in x_train:\n",
    "        dic = get_dipeptide_dictionary(each)\n",
    "        list_dictionary.append(dic)\n",
    "\n",
    "    return list_dictionary\n",
    "\n",
    "def getvector(vector_dictionary, dipeptide_seq):\n",
    "    \"\"\"\n",
    "    Преобразует список словарей дипептидных векторов в список векторов фиксированной длины.\n",
    "\n",
    "    Каждый вектор представляет собой векторное представление одной последовательности, где каждый элемент вектора\n",
    "    соответствует частоте одного дипептида из списка dipeptide_seq в этой последовательности.\n",
    "\n",
    "    Параметры:\n",
    "    vector_dictionary : list of dict\n",
    "        Список словарей дипептидных векторов для каждой последовательности.\n",
    "    dipeptide_seq : list of str\n",
    "        Список всех возможных дипептидов, определяющий порядок и количество элементов в итоговом векторе.\n",
    "\n",
    "    Возвращает:\n",
    "    list of list of float\n",
    "        Список векторов, где каждый вектор представляет дипептидное векторное представление одной последовательности.\n",
    "\n",
    "    Пример использования:\n",
    "    final_vector = getvector(list_dictionary, dipeptide_seq)\n",
    "    # Возвращает список векторов для каждой последовательности.\n",
    "    \"\"\"\n",
    "    final_vector = []  # Инициализация списка для хранения итоговых векторов\n",
    "\n",
    "    # Перебор каждого словаря в списке\n",
    "    for dic in vector_dictionary:\n",
    "        vec = [0.0] * len(dipeptide_seq)\n",
    "        for item in dic:\n",
    "            if item in dipeptide_seq:\n",
    "                index = dipeptide_seq.index(item)\n",
    "                vec[index] = dic[item]\n",
    "\n",
    "        final_vector.append(vec)\n",
    "\n",
    "    return final_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Rw2w4-EUUXJd"
   },
   "outputs": [],
   "source": [
    "# Hepls для извлечения векторов для транслирования модели\n",
    "training_vector_dict = getlist_of_dictionary(x_train)\n",
    "\n",
    "X_Train = getvector(training_vector_dict, dipeptide_seq)\n",
    "\n",
    "## Данные преобразуются в массив numpy.\n",
    "x = np.array(X_Train)\n",
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBTCTkfAVLx0",
    "outputId": "92d22dcc-a12e-4af6-891a-40ae061cdcba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разделим данные на обучающие и проверочные 70% и 30% соответственно\n",
      "Размер обучающих данных :  (27237, 780)\n",
      "Размер проверочных данных :  (11673, 780)\n"
     ]
    }
   ],
   "source": [
    "# Разделим данные на обучающие и проверочные 70% и 30% соответственно.\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Разделим данные на обучающие и проверочные 70% и 30% соответственно')\n",
    "\n",
    "print('Размер обучающих данных : ',x_train.shape)\n",
    "print('Размер проверочных данных : ',x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q10_W10JWVI1",
    "outputId": "8805d690-db94-464d-e4d0-adda90b4e8d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер проверочных данных :  (2000, 780)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test data\"\"\"\n",
    "\n",
    "## То же извлечение дипептидного вектора из тестовых данных\n",
    "\n",
    "ID = []\n",
    "test_sequence = []\n",
    "\n",
    "with open(test_data) as f:\n",
    "    for line in f:\n",
    "        after_split = line.split(\",\")\n",
    "        if after_split[0] == 'ID':\n",
    "            continue;\n",
    "        ID.append(after_split[0])\n",
    "        test_sequence.append(after_split[1][:-1])\n",
    "\n",
    "## То же извлечение дипептидного вектора из тестовых данных\n",
    "\n",
    "testing_vector_dict = getlist_of_dictionary(test_sequence)\n",
    "x_test = getvector(testing_vector_dict, dipeptide_seq)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "print('Размер проверочных данных : ',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bx7uwRg8W89O"
   },
   "outputs": [],
   "source": [
    "\"\"\"Normalization\"\"\"\n",
    "\n",
    "# Масштабирование данных с помощью min-max скалера\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SlbXd8rlZEOr"
   },
   "outputs": [],
   "source": [
    "\"\"\"Feature Reduction\"\"\"\n",
    "\n",
    "# С помощью анализа главных компонент (PCA) число признаков уменьшается с 318 до меньшего.\n",
    "# Сокращение числа функций до 125\n",
    "pca = PCA(n_components=125)\n",
    "\n",
    "x_train_pca = pca.fit_transform(X_train)\n",
    "x_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yP7PFSDzaVcm"
   },
   "outputs": [],
   "source": [
    "# Применение RepeatedStratifiedKFold\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5,\n",
    "                                    n_repeats=3,\n",
    "                                    random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dQik8OYbcIfx"
   },
   "outputs": [],
   "source": [
    "def model_training(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Предоставляет интерфейс для выбора и обучения различных моделей машинного обучения с последующей записью предсказаний в файл.\n",
    "\n",
    "    Функция предлагает пользователю выбрать одну из предложенных моделей машинного обучения, проводит настройку параметров модели с использованием\n",
    "    GridSearchCV, обучает модель на обучающем наборе данных, вычисляет точность на валидационном наборе, делает предсказания на тестовом наборе данных\n",
    "    и записывает эти предсказания в файл. Поддерживаемые модели включают Случайный лес, Многослойный персептрон, Наивный Байес, XGBoost и KNN.\n",
    "\n",
    "    Параметры:\n",
    "    Нет параметров.\n",
    "\n",
    "    Возвращает:\n",
    "    Ничего не возвращает. Результат работы - файлы с предсказаниями для выбранной модели.\n",
    "\n",
    "    Примеры использования:\n",
    "    model_training() # Запуск функции приведет к интерактивному выбору модели и последующему обучению с записью предсказаний в файл.\n",
    "    \"\"\"\n",
    "\n",
    "    def writeintopredfile(filename, model_pre):\n",
    "        \"\"\"\n",
    "        Записывает предсказания модели в файл.\n",
    "\n",
    "        Аргументы:\n",
    "        filename : str\n",
    "            Имя файла для сохранения предсказаний.\n",
    "        model_pre : list\n",
    "            Список предсказаний модели.\n",
    "        \"\"\"\n",
    "        f = open(filename,'w')\n",
    "        s = \"ID,Метка\\n\"\n",
    "        c = 0\n",
    "        for i in model_pre:\n",
    "            s = s + ID[c] + \",\" + i.__str__() + \"\\n\"\n",
    "            c += 1\n",
    "\n",
    "        f.write(s)\n",
    "        f.close()\n",
    "\n",
    "    print('')\n",
    "\n",
    "    print('Выберите модель: ')\n",
    "    print('1. Случайный лес')\n",
    "    print('2. Многослойный персептрон')\n",
    "    print('3. Наивный Байес')\n",
    "    print('4. XGBoost')\n",
    "    print('5. KNN')\n",
    "\n",
    "    print('')\n",
    "\n",
    "    k = int(input('Введите номер для выбора модели: '))\n",
    "\n",
    "    if k == 1 :\n",
    "\n",
    "        # Настройка параметров с помощью GridSearchCV\n",
    "        param_grid = {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [80, 90, 100],\n",
    "            'max_features': [2, 3],\n",
    "            'n_estimators': [300, 400]\n",
    "        }\n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                                  cv = 3, n_jobs = -1, verbose = 100)\n",
    "        # Модель обучается с использованием разделенных данных\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        # Из заданных параметров выводятся лучшие.\n",
    "        print('Лучшие параметры: ', grid_search.best_params_)\n",
    "        print('Точность на валидации: ', accuracy_score(y_val, grid_search.predict(x_val)))\n",
    "        ans_RF = grid_search.predict(x_test)\n",
    "        print('Предсказание на тестовых данных: ', ans_RF)\n",
    "        writeintopredfile('RF_86.csv', ans_RF)\n",
    "\n",
    "    elif k == 2 :\n",
    "\n",
    "        # Количество итераций установлено как 100. Это было проверено с различными значениями максимальных итераций.\n",
    "        mlp_gs = MLPClassifier(max_iter=100)\n",
    "        # Настройка параметров с помощью GridSearchCV\n",
    "        parameter_space = {\n",
    "            'hidden_layer_sizes': [(10,30,10)],\n",
    "            'activation': ['tanh'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.05],\n",
    "            'learning_rate': ['constant'],\n",
    "        }\n",
    "        # Кросс-валидация установлена как 10.\n",
    "        clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, verbose = 50 ,cv=10)\n",
    "        # Модель обучается с использованием разделенных данных\n",
    "        clf.fit(x_train, y_train)\n",
    "        # Из заданных параметров выводятся лучшие.\n",
    "        print('Лучшие найденные параметры:\\n', clf.best_params_)\n",
    "        print('Оценка на валидации: ', accuracy_score(y_val, clf.predict(x_val)))\n",
    "        # Производится предсказание на тестовых данных\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print('Предсказание на тестовых данных: ', y_pred)\n",
    "        writeintopredfile('MLP_67.csv', y_pred)\n",
    "\n",
    "    elif k == 3 :\n",
    "\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "        np.random.seed(999)\n",
    "\n",
    "        nb_classifier = GaussianNB()\n",
    "\n",
    "        params_NB = {'var_smoothing': np.logspace(0, -9, num=100)}\n",
    "\n",
    "        gs_NB = GridSearchCV(estimator=nb_classifier,\n",
    "                            param_grid=params_NB,\n",
    "                            cv=cv_method,\n",
    "                            verbose=100,\n",
    "                            scoring='accuracy')\n",
    "\n",
    "        gs_NB.fit(x_train, y_train)\n",
    "        print('Лучшие параметры: ', gs_NB.best_params_)\n",
    "        print('Лучшая оценка: ', gs_NB.best_score_)\n",
    "\n",
    "        ans_NB= gs_NB.predict(x_test)\n",
    "        print('Предсказание на тестовых данных: ', ans_NB)\n",
    "        writeintopredfile('NB_65.csv', ans_NB)\n",
    "\n",
    "    elif k == 4:\n",
    "\n",
    "        validationPredictions = []\n",
    "        trainingPredictions = []\n",
    "        xgbClassifiersUsed = []\n",
    "\n",
    "        xgboostClassifier = xgb.XGBClassifier(booster='gbtree', n_estimators=100, max_depth=6)\n",
    "        xgboostClassifier.fit(x_train, y_train)\n",
    "\n",
    "        xgbClassifiersUsed.append(xgboostClassifier)\n",
    "\n",
    "        YBoostTrain = xgboostClassifier.predict(x_train)\n",
    "        YBoostValidate = xgboostClassifier.predict(x_val)\n",
    "\n",
    "        print(\"\\nXGBoost Forest :-\")\n",
    "        print(\"Точность на обучающем наборе: \", accuracy_score(y_train, YBoostTrain))\n",
    "        print(\"Точность на валидационном наборе: \", accuracy_score(y_val, YBoostValidate))\n",
    "\n",
    "        ans_XGB = xgboostClassifier.predict(x_test)\n",
    "\n",
    "        print('Предсказание на тестовых данных: ', ans_XGB)\n",
    "\n",
    "        writeintopredfile('XGB_71.csv', ans_XGB)\n",
    "\n",
    "    elif k == 5 :\n",
    "\n",
    "        params_KNN = {'n_neighbors': [4],\n",
    "                      'p': [1]}\n",
    "\n",
    "        gs_KNN = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                              param_grid=params_KNN,\n",
    "                              cv=cv_method,\n",
    "                              verbose=100,  # Чем выше значение, тем больше сообщений\n",
    "                              scoring='accuracy',\n",
    "                              return_train_score=True)\n",
    "\n",
    "        gs_KNN.fit(x_train, y_train)\n",
    "\n",
    "        gs_KNN.best_params_\n",
    "\n",
    "        accuracy_score(y_val, gs_KNN.predict(x_val))\n",
    "\n",
    "        ans_KNN = gs_KNN.predict(x_test)\n",
    "\n",
    "        writeintopredfile('KNN_65.csv', ans_NB)\n",
    "\n",
    "    else:\n",
    "        print('Вы ввели неверные данные')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "Duetz3B8hyu8",
    "outputId": "98074e89-0afd-42aa-f19c-99bb57773485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Выберите модель: \n",
      "1. Случайный лес\n",
      "2. Многослойный персептрон\n",
      "3. Наивный Байес\n",
      "4. XGBoost\n",
      "5. KNN\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Введите номер для выбора модели:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV 1/3; 1/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=300\n",
      "[CV 3/3; 1/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=300\n",
      "[CV 2/3; 1/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=300\n",
      "[CV 2/3; 3/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=300\n",
      "[CV 1/3; 3/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=300\n",
      "[CV 3/3; 3/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=300\n",
      "[CV 2/3; 4/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=400\n",
      "[CV 2/3; 2/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=400\n",
      "[CV 1/3; 2/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=400\n",
      "[CV 3/3; 6/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=400\n",
      "[CV 1/3; 4/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=400\n",
      "[CV 3/3; 5/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=300\n",
      "[CV 2/3; 5/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=300\n",
      "[CV 3/3; 4/12] START bootstrap=True, max_depth=80, max_features=3, n_estimators=400\n",
      "[CV 3/3; 2/12] START bootstrap=True, max_depth=80, max_features=2, n_estimators=400\n",
      "[CV 2/3; 6/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=400\n",
      "[CV 3/3; 8/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=400\n",
      "[CV 2/3; 8/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=400\n",
      "[CV 3/3; 11/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=300\n",
      "[CV 3/3; 9/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=300\n",
      "[CV 2/3; 12/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=400\n",
      "[CV 1/3; 7/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=300\n",
      "[CV 3/3; 7/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=300\n",
      "[CV 1/3; 9/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=300\n",
      "[CV 2/3; 7/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=300\n",
      "[CV 1/3; 8/12] START bootstrap=True, max_depth=90, max_features=3, n_estimators=400\n",
      "[CV 1/3; 6/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=400\n",
      "[CV 3/3; 12/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=400\n",
      "[CV 2/3; 10/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=400\n",
      "[CV 1/3; 5/12] START bootstrap=True, max_depth=90, max_features=2, n_estimators=300\n",
      "[CV 1/3; 11/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=300\n",
      "[CV 2/3; 11/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=300\n",
      "[CV 1/3; 10/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=400\n",
      "[CV 1/3; 12/12] START bootstrap=True, max_depth=100, max_features=3, n_estimators=400\n",
      "[CV 2/3; 9/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=300\n",
      "[CV 3/3; 10/12] START bootstrap=True, max_depth=100, max_features=2, n_estimators=400\n",
      "[CV 1/3; 1/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=300;, score=0.827 total time=  10.0s\n",
      "[CV 2/3; 3/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=300;, score=0.817 total time=  10.3s\n",
      "[CV 1/3; 3/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=300;, score=0.823 total time=  10.4s\n",
      "[CV 3/3; 3/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=300;, score=0.822 total time=  10.7s\n",
      "[CV 3/3; 1/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=300;, score=0.821 total time=  11.7s\n",
      "[CV 2/3; 1/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=300;, score=0.817 total time=  11.8s\n",
      "[CV 2/3; 9/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=300;, score=0.823 total time=  11.7s\n",
      "[CV 2/3; 5/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=300;, score=0.821 total time=  11.8s\n",
      "[CV 1/3; 9/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=300;, score=0.827 total time=  11.8s\n",
      "[CV 3/3; 5/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=300;, score=0.823 total time=  12.0s\n",
      "[CV 1/3; 5/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=300;, score=0.824 total time=  12.2s\n",
      "[CV 3/3; 9/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=300;, score=0.823 total time=  12.2s\n",
      "[CV 2/3; 11/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=300;, score=0.817 total time=  12.3s\n",
      "[CV 2/3; 7/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=300;, score=0.817 total time=  12.3s\n",
      "[CV 1/3; 11/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=300;, score=0.823 total time=  12.5s\n",
      "[CV 3/3; 11/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=300;, score=0.825 total time=  12.5s\n",
      "[CV 1/3; 7/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=300;, score=0.821 total time=  12.6s\n",
      "[CV 3/3; 7/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=300;, score=0.820 total time=  12.6s\n",
      "[CV 3/3; 6/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=400;, score=0.825 total time=  13.8s\n",
      "[CV 1/3; 2/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=400;, score=0.827 total time=  13.8s\n",
      "[CV 3/3; 2/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=400;, score=0.823 total time=  14.5s\n",
      "[CV 2/3; 2/12] END bootstrap=True, max_depth=80, max_features=2, n_estimators=400;, score=0.820 total time=  15.0s\n",
      "[CV 1/3; 4/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=400;, score=0.822 total time=  15.0s\n",
      "[CV 1/3; 6/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=400;, score=0.824 total time=  15.1s\n",
      "[CV 2/3; 10/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=400;, score=0.820 total time=  15.2s\n",
      "[CV 2/3; 6/12] END bootstrap=True, max_depth=90, max_features=2, n_estimators=400;, score=0.823 total time=  15.4s\n",
      "[CV 3/3; 4/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=400;, score=0.821 total time=  15.5s\n",
      "[CV 2/3; 4/12] END bootstrap=True, max_depth=80, max_features=3, n_estimators=400;, score=0.817 total time=  15.6s\n",
      "[CV 1/3; 10/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=400;, score=0.829 total time=  15.6s\n",
      "[CV 3/3; 10/12] END bootstrap=True, max_depth=100, max_features=2, n_estimators=400;, score=0.824 total time=  15.6s\n",
      "[CV 2/3; 8/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=400;, score=0.820 total time=  15.8s\n",
      "[CV 2/3; 12/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=400;, score=0.820 total time=  16.0s\n",
      "[CV 3/3; 8/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=400;, score=0.821 total time=  16.1s\n",
      "[CV 1/3; 12/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=400;, score=0.824 total time=  16.2s\n",
      "[CV 3/3; 12/12] END bootstrap=True, max_depth=100, max_features=3, n_estimators=400;, score=0.819 total time=  16.3s\n",
      "[CV 1/3; 8/12] END bootstrap=True, max_depth=90, max_features=3, n_estimators=400;, score=0.824 total time=  16.4s\n",
      "Лучшие параметры:  {'bootstrap': True, 'max_depth': 100, 'max_features': 2, 'n_estimators': 400}\n",
      "Точность на валидации:  0.8632742225648934\n",
      "Предсказание на тестовых данных:  ['0' '0' '0' ... '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "model_training(x_train, x_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
